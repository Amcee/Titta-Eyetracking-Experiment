{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f724fbe9",
   "metadata": {},
   "source": [
    "## Extract trial data\n",
    "\n",
    "Takes output pickle (.pkl) files recorded with Titta and divides them into trials using messages sent during the experiment. Will output a folder with trial data in .csv-format (one file for each trial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8d19bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350aeb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_trial_data(df_et_data, df_msg, msg_onset, msg_offset):\n",
    "    ''' Extracts data from one trial associated with specific onset and offset messages.\n",
    "\n",
    "    Args:\n",
    "        df_et_data - Pandas dataframe with sample et-data (output from Titta)\n",
    "        df_msg - Pandas dataframe containing messages\n",
    "        msg_onset (str) - message sent at stimulus onset (e.g., onset_polarbear)\n",
    "        msg_offset (str) - message sent at stimulus onset (e.g., offset_polarbear)\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        df - dataframe with data from one trial\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Find timestamps for data belonging to this stimulus\n",
    "    start_idx = np.where(df_msg.msg == msg_onset)[0][0]\n",
    "    stop_idx = np.where(df_msg.msg == msg_offset)[0][0]\n",
    "\n",
    "    start_time_stamp = df_msg.system_time_stamp[start_idx]\n",
    "    stop_time_stamp = df_msg.system_time_stamp[stop_idx]\n",
    "\n",
    "    # print(start_idx, stop_idx, start_time_stamp, stop_time_stamp)\n",
    "    #\n",
    "    # Cut out samples belonging to this stimulus\n",
    "    fix_idx_start = np.searchsorted(df_et_data.system_time_stamp,\n",
    "                                    start_time_stamp)\n",
    "    fix_idx_stop = np.searchsorted(df_et_data.system_time_stamp,\n",
    "                                   stop_time_stamp)\n",
    "    df_stim = df_et_data.iloc[fix_idx_start:fix_idx_stop].copy()\n",
    "\n",
    "    return df_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e83fa615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Trial im3.jpeg.tsv written to folder  c:\\git\\Titta\\resources\\trials\\participant1\n",
      "Trial im2.jpeg.tsv written to folder  c:\\git\\Titta\\resources\\trials\\participant1\n",
      "Trial im1.jpeg.tsv written to folder  c:\\git\\Titta\\resources\\trials\\participant1\n",
      "Folder is already there\n",
      "Trial im3.jpeg.tsv written to folder  c:\\git\\Titta\\resources\\trials\\participant2\n",
      "Trial im2.jpeg.tsv written to folder  c:\\git\\Titta\\resources\\trials\\participant2\n",
      "Trial im1.jpeg.tsv written to folder  c:\\git\\Titta\\resources\\trials\\participant2\n"
     ]
    }
   ],
   "source": [
    "# header / column names\n",
    "header = ['device_time_stamp',\n",
    "         'system_time_stamp',\n",
    "         'left_gaze_point_on_display_area_x',\n",
    "         'left_gaze_point_on_display_area_y',\n",
    "         'left_gaze_point_in_user_coordinate_system_x',\n",
    "         'left_gaze_point_in_user_coordinate_system_y',\n",
    "         'left_gaze_point_in_user_coordinate_system_z',\n",
    "         'left_gaze_origin_in_trackbox_coordinate_system_x',\n",
    "         'left_gaze_origin_in_trackbox_coordinate_system_y',\n",
    "         'left_gaze_origin_in_trackbox_coordinate_system_z',\n",
    "         'left_gaze_origin_in_user_coordinate_system_x',\n",
    "         'left_gaze_origin_in_user_coordinate_system_y',\n",
    "         'left_gaze_origin_in_user_coordinate_system_z',\n",
    "         'left_pupil_diameter',\n",
    "         'left_pupil_validity',\n",
    "         'left_gaze_origin_validity',\n",
    "         'left_gaze_point_validity',\n",
    "         'right_gaze_point_on_display_area_x',\n",
    "         'right_gaze_point_on_display_area_y',\n",
    "         'right_gaze_point_in_user_coordinate_system_x',\n",
    "         'right_gaze_point_in_user_coordinate_system_y',\n",
    "         'right_gaze_point_in_user_coordinate_system_z',\n",
    "         'right_gaze_origin_in_trackbox_coordinate_system_x',\n",
    "         'right_gaze_origin_in_trackbox_coordinate_system_y',\n",
    "         'right_gaze_origin_in_trackbox_coordinate_system_z',\n",
    "         'right_gaze_origin_in_user_coordinate_system_x',\n",
    "         'right_gaze_origin_in_user_coordinate_system_y',\n",
    "         'right_gaze_origin_in_user_coordinate_system_z',\n",
    "         'right_pupil_diameter',\n",
    "         'right_pupil_validity',\n",
    "         'right_gaze_origin_validity',\n",
    "         'right_gaze_point_validity']\n",
    "\n",
    "# Read messages and et data all participants (one .pkl-file per participant)\n",
    "files = Path.cwd().glob('*.pkl')\n",
    "\n",
    "for f in files:\n",
    "\n",
    "    pid = str(f).split(os.sep)[-1][:-4]\n",
    "\n",
    "    fh = open(f, 'rb')\n",
    "    gaze_data_container = pickle.load(fh)\n",
    "    msg_container = pickle.load(fh)\n",
    "\n",
    "    # Convert to pandas dataframes\n",
    "    df = pd.DataFrame(gaze_data_container, columns=header)\n",
    "    df_msg = pd.DataFrame(msg_container, columns=['system_time_stamp', 'msg'])\n",
    "\n",
    "    # Read message for onset and offset\n",
    "    # Assumption is that messages are on the form (must be unique)\n",
    "    # 'onset_stimulusname' for the onset of a stimulus and\n",
    "    # 'offset_stimulusname'for the offset of a stimulus\n",
    "    onset = []\n",
    "    offset = []\n",
    "    for i, row in df_msg.iterrows():\n",
    "\n",
    "        if 'onset' in row.msg:\n",
    "            onset.append(row.msg)\n",
    "        if 'offset' in row.msg:\n",
    "            offset.append(row.msg)\n",
    "    trial_msg = zip(onset, offset)\n",
    "\n",
    "    # Create a folder to put the trials\n",
    "    path = Path.cwd() / 'trials' / pid\n",
    "    try:\n",
    "        path.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError:\n",
    "        print(\"Folder is already there\")\n",
    "    else:\n",
    "        print(\"Folder was created\")\n",
    "\n",
    "    # Extract relevant trial data and save in format required by I2MC\n",
    "    for t in trial_msg:\n",
    "        df_trial = extract_trial_data(df, df_msg, t[0], t[1])\n",
    "\n",
    "        filename = t[0].split('_')[1] + '.tsv'\n",
    "        df_trial.to_csv(str(path) + os.sep + filename, sep='\\t')\n",
    "\n",
    "        print('Trial ' + filename + \" written to folder \", path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed15aa3",
   "metadata": {},
   "source": [
    "## Detect fixations from extracted trial data\n",
    "\n",
    "OBS! Before running the below cell, download and extract the I2MC algorithm (https://github.com/dcnieho/I2MC_Python) to the folder resources/I2MC. The name of the extracted folder must be 'I2MC_Python-master'.\n",
    "\n",
    "Running the cell will prompt the user to download the I2MC algorithm (if not already done), and move trial data to the approriate folder in the I2MC folder structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14557554",
   "metadata": {},
   "source": [
    "### 1. Copy data to required I2MC folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e7403f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed old data\n",
      "Copied data to c:\\git\\Titta\\resources\\I2MC\\I2MC_Python-master\\example\\example_data\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "I2MC_main_path = Path.cwd() / 'I2MC' / 'I2MC_Python-master' / 'example'\n",
    "\n",
    "I2MC_main = I2MC_main_path / 'I2MC_example.py'\n",
    "if not I2MC_main.is_file():\n",
    "    print('It appears that I2MC is not available. please follow the\\\n",
    " instructions in /resources/I2MC/get_I2MC.txt to download it.')\n",
    "    raise FileNotFoundError\n",
    "\n",
    "# First remove example data found when downloading I2MC\n",
    "example_data_path = I2MC_main_path / 'example_data'\n",
    "if example_data_path.is_dir():\n",
    "    shutil.rmtree(example_data_path)\n",
    "    print('Removed old data')\n",
    "\n",
    "\n",
    "# Move trial data you extracted to the right folder I2MC\n",
    "shutil.copytree(str(Path.cwd() / 'trials'), str(example_data_path))\n",
    "print('Copied data to ' + str(example_data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c52ecc",
   "metadata": {},
   "source": [
    "### 2. Run the I2MC algorithm\n",
    "\n",
    "Open the jupyter notebook I2MC_example.ipynb located in resources\\I2MC\\I2MC_Python-master\\example.\n",
    "OBS! Before running the notebook, adjust the settings to match your experimental setup. Check under 'Options' in the beginning of the file. Also make sure Titta is use when importing data. Replace the line (in 'Start the algorithm' section)\n",
    "\n",
    "data = imp.tobii_TX300(file_name, [opt['xres'], opt['yres']])\n",
    "\n",
    "with\n",
    "\n",
    "data = imp.Titta(file_name, [opt['xres'], opt['yres']])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
